# Data Module for Algorithmic Trading System

## Overview

The Data module serves as the foundation for market data acquisition, processing, and management in our algorithmic trading system. It is designed to work seamlessly with the event-driven architecture, providing a clean and efficient data pipeline for strategy components.

## Features

- **Flexible Data Sources**: Support for various data sources (CSV, APIs, databases)
- **Event-Based Data Flow**: Integration with the event system for real-time data processing
- **Data Transformation**: Tools for resampling, normalization, and other transformations
- **Historical Backtesting**: Efficient replay of historical data for strategy testing
- **Extensible Design**: Easily add new data sources and transformers

## Architecture

The Data module follows a modular design with clear separation of concerns:

1. **Data Sources**: Responsible for acquiring raw data
2. **Data Handlers**: Manage data flow and integration with the event system
3. **Transformers**: Provide tools for data processing and feature engineering

![Data Module Architecture](docs/images/data_module_architecture.png)

## Core Components

### DataSourceBase

Abstract base class for all data sources. Implements methods to:
- Get data for a specific symbol and date range
- Check if data is available

### DataHandlerBase

Abstract base class for data handlers. Implements methods to:
- Load data for specified symbols
- Iterate through data (get_next_bar)
- Reset the handler state
- Manage bar history

### Transformers

Utility classes for data transformation:
- **Resampler**: Time-based resampling (e.g., 1m -> 5m, 1h -> 1d)
- **Normalizer**: Data normalization (Z-score, min-max, robust scaling)

### ComponentRegistry and Factory

Registry and factory pattern implementation for dynamic component discovery and creation.

## Integration with Event System

The Data module is tightly integrated with the event system:

1. Data handlers emit `BarEvent` objects to the event bus
2. Strategy components subscribe to these events
3. Signals generated by strategies are emitted back to the event bus
4. Execution components act on these signals

This event-driven approach allows for:
- Loose coupling between components
- Real-time processing of market data
- Efficient backtesting with the same code

## Example Usage

### Loading Historical Data

```python
from core.events.event_bus import EventBus
from data.sources.csv_handler import CSVDataSource
from data.historical_data_handler import HistoricalDataHandler

# Create event system
event_bus = EventBus()

# Create data source and handler
data_source = CSVDataSource('./data')
data_handler = HistoricalDataHandler(data_source, event_bus)

# Load data
data_handler.load_data(['AAPL', 'MSFT'], 
                      start_date='2022-01-01', 
                      end_date='2022-12-31',
                      timeframe='1d')

# Process data
while True:
    bar = data_handler.get_next_bar('AAPL')
    if bar is None:
        break
    # Bar events are automatically emitted to the event bus
```

### Transforming Data

```python
from data.transformers.resampler import Resampler
from data.transformers.normalizer import Normalizer
import pandas as pd

# Create sample data
df = pd.read_csv('AAPL_1d.csv', index_col='date', parse_dates=True)

# Resample from daily to weekly
resampler = Resampler(rule='W')
weekly_data = resampler.resample(df)

# Normalize price data
normalizer = Normalizer(method='zscore', columns=['open', 'high', 'low', 'close'])
normalized_data = normalizer.fit_transform(df)
```

### Running a Backtest

```python
from core.events.event_bus import EventBus
from core.events.event_manager import EventManager
from data.sources.csv_handler import CSVDataSource
from data.historical_data_handler import HistoricalDataHandler
from my_strategy import MyStrategy

# Create event system
event_bus = EventBus()
event_manager = EventManager(event_bus)

# Create components
data_source = CSVDataSource('./data')
data_handler = HistoricalDataHandler(data_source, event_bus)
strategy = MyStrategy(['AAPL'], event_bus)

# Register components
event_manager.register_component('strategy', strategy, [EventType.BAR])

# Load and process data
data_handler.load_data(['AAPL'], timeframe='1d')
while True:
    bar = data_handler.get_next_bar('AAPL')
    if bar is None:
        break

# Check results
print(f"Generated {len(strategy.signals)} signals")
```

## Testing

The Data module includes comprehensive tests:

- **Unit tests**: Test individual components in isolation
- **Integration tests**: Test component interaction
- **System tests**: Test integration with the full trading system

Run the tests with:

```bash
# Run all tests
python -m unittest discover tests

# Run specific test
python -m unittest tests.test_data_handler
```

## Extending the System

### Adding a New Data Source

1. Create a new class implementing `DataSourceBase`
2. Implement the required methods (`get_data`, `is_available`)
3. Register with the component registry

Example:

```python
from data.data_source_base import DataSourceBase
import yfinance as yf

class YahooFinanceDataSource(DataSourceBase):
    def get_data(self, symbol, start_date=None, end_date=None, timeframe='1d'):
        ticker = yf.Ticker(symbol)
        df = ticker.history(period='max', interval=timeframe, 
                           start=start_date, end=end_date)
        # Rename columns to match our standards
        df = df.rename(columns={'Open': 'open', 'High': 'high', 
                               'Low': 'low', 'Close': 'close', 
                               'Volume': 'volume'})
        return df
    
    def is_available(self, symbol, start_date=None, end_date=None, timeframe='1d'):
        try:
            ticker = yf.Ticker(symbol)
            info = ticker.info
            return 'symbol' in info
        except:
            return False

# Register with factory
from data import default_factory
default_factory.register('yahoo', YahooFinanceDataSource)
```

### Creating a Custom Transformer

1. Create a new class in the `transformers` package
2. Implement methods for data transformation
3. Use with data handlers or directly with data

## Future Enhancements

- Real-time data streaming via WebSockets
- Adaptive data resampling based on market conditions
- Advanced feature engineering components
- Data caching for improved performance
- Multi-source data fusion

## Contributing

Contributions to the Data module are welcome:

1. Clone the repository
2. Create a feature branch
3. Add your changes
4. Write tests for new functionality
5. Submit a pull request

Please follow the established coding style and include comprehensive tests.